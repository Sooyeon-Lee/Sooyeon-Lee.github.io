---
title: "Lab Experiment Studies"
collection: portfolio
permalink: /portfolio/LabExp
excerpt: "Through iterative lab studies, we investigated and evaluated effectiveness and user experience of the smart camera prosthetics and feedback interface prototype (wearable technology + single or multi-modality of auditory or haptic sense) that support information delivery and navigational guidance for people with visual impairments with using context of grocery shopping."
---

<center>
<h2>Lab Experiment Study 1: Five Signaling Conditions</h2>
</center>

<h3>Goals</h3>
<ul>
  <li> Investigated experience and effectiveness of five signaling designs to guide item acquisition </li>   
</ul> 
  
<h3>Designs</h3>
<ul>
    <li> 5 feedback types: Tones; Speech; Haptic; Speech + Haptic; Tones + Haptic </li>
    <li> Wizard of Oz mockup of grocery shelves; prototype haptic glove system; camera </li>
    <li> Pilot study - 63 blind-folded undergrad students </li>
    <li> Main study - 11 people with visual impairments </li>
</ul> 
  
<h3>Findings</h3>
<ul>
    <li> Arm-and-hand navigation support experienced as helpful </li>
    <li> Most effective and preferred feedback condition – Speech + Haptic </li>
    <li> Active engagement, social learning, and “shopping” </li>
</ul> 

<h3>User Interface Prototype and Experimental Study</h3>
<img width=200 height=200 src="https://Sooyeon-Lee.github.io/images/Labex1_1.png" border="0"/>
<img width=200 height=200 src="https://Sooyeon-Lee.github.io/images/Labex1_2.png" border="0"/>
<img width=200 height=200 src="https://Sooyeon-Lee.github.io/images/Labex1_3.png" border="0"/>
        
<h3>Work Published in <a href="https://Sooyeon-Lee.github.io/files/2017_reaching.pdf">ASSETS</a>/<a href="https://Sooyeon-Lee.github.io/files/ASSETS_Poster_2017.pdf">POSTER</a> and <a href="https://Sooyeon-Lee.github.io/files/2017_third.pdf">Computer Magazine</a></h3>

<h2>Lab Experiment Study 2: Two Designs for Multimodal Signaling</h2>

<h3>Goals</h3>
<ul>
  <li> Investigated two multimodal designs (speech and haptic vibration) to guide item acquisition </li>   
</ul> 

<h3>Designs</h3>
<ul>
    <li> Two speech+vibration conditions: Continuous versus Boundary condition </li>
    <li> Wizard of Oz mockup grocery shelves; haptic glove + bone conduction headset prototype system </li>
    <li> Pilot study – 5 blind folded sighted people </li>
    <li> Exploratory study – 12 visually impaired attendees at NFB PA State Convention </li>
    <li> Main study – 11 visually impaired people </li>
</ul> 

<h3>Findings</h3>
<ul>
    <li> Both conditions were more effective than the earlier multimodal combinations from study #1, but no overall preference </li>
    <li> Personal level preferences and rationales </li>
    <li> A paper describing this work is in preparation</li>
</ul> 

<h3>Experimental Study</h3>
<img width=200 height=200 src="https://Sooyeon-Lee.github.io/images/Labex2_1.png" border="0"/>
<img width=200 height=200 src="https://Sooyeon-Lee.github.io/images/Labex2_2.png" border="0"/>
